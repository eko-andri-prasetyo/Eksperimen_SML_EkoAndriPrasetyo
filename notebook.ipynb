{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZLRMFl0JyyQ"
   },
   "source": [
    "# **1. Perkenalan Dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hssSDn-5n3HR"
   },
   "source": [
    "Tahap pertama, Anda harus mencari dan menggunakan dataset dengan ketentuan sebagaimana yang sudah ditentukan.\n",
    "\n",
    "### Dataset yang digunakan\n",
    "Saya menggunakan dataset **Credit Scoring (synthetic)** yang disimpan di repository ini.\n",
    "\n",
    "- **Sumber data (link):** https://github.com/eko-andri-prasetyo/Eksperimen_SML_EkoAndriPrasetyo/blob/main/creditscoring_raw/creditscoring_raw.csv\n",
    "- **Lokasi file raw:** `creditscoring_raw/creditscoring_raw.csv`\n",
    "- **Target:** `target` (0/1)\n",
    "- **Fitur utama:** `age`, `monthly_income`, `loan_amount`, `tenure_months`, `num_credit_lines`, `job_type`, `education_level`, `city`, `marital_status`, `has_previous_default`.\n",
    "\n",
    "Catatan: Dataset ini bersifat **synthetic/dibuat untuk kebutuhan latihan submission**. Referensi sumber data ditautkan ke file dataset raw di repository agar dapat diakses reviewer dengan mudah.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKADPWcFKlj3"
   },
   "source": [
    "# **2. Import Library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgA3ERnVn84N"
   },
   "source": [
    "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning atau deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlmvjLY9M4Yj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3YIEnAFKrKL"
   },
   "source": [
    "# **3. Memuat Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ey3ItwTen_7E"
   },
   "source": [
    "Pada tahap ini, Anda perlu memuat dataset ke dalam notebook. Jika dataset dalam format CSV, Anda bisa menggunakan pustaka pandas untuk membacanya. Pastikan untuk mengecek beberapa baris awal dataset untuk memahami strukturnya dan memastikan data telah dimuat dengan benar.\n",
    "\n",
    "Jika dataset berada di Google Drive, pastikan Anda menghubungkan Google Drive ke Colab terlebih dahulu. Setelah dataset berhasil dimuat, langkah berikutnya adalah memeriksa kesesuaian data dan siap untuk dianalisis lebih lanjut.\n",
    "\n",
    "Jika dataset berupa unstructured data, silakan sesuaikan dengan format seperti kelas Machine Learning Pengembangan atau Machine Learning Terapan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHCGNTyrM5fS"
   },
   "outputs": [],
   "source": [
    "RAW_PATH = Path(\"creditscoring_raw/creditscoring_raw.csv\")\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgZkbJLpK9UR"
   },
   "source": [
    "# **4. Exploratory Data Analysis (EDA)**\n",
    "\n",
    "Pada tahap ini, Anda akan melakukan **Exploratory Data Analysis (EDA)** untuk memahami karakteristik dataset.\n",
    "\n",
    "Tujuan dari EDA adalah untuk memperoleh wawasan awal yang mendalam mengenai data dan menentukan langkah selanjutnya dalam analisis atau pemodelan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKeejtvxM6X1"
   },
   "outputs": [],
   "source": [
    "# Info ringkas dataset\n",
    "df.info()\n",
    "\n",
    "# Statistik deskriptif kolom numerik\n",
    "df.describe().T\n",
    "\n",
    "# Cek missing values\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "missing[missing > 0]\n",
    "\n",
    "# Distribusi target (jika ada)\n",
    "if \"target\" in df.columns:\n",
    "    df[\"target\"].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpgHfgnSK3ip"
   },
   "source": [
    "# **5. Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COf8KUPXLg5r"
   },
   "source": [
    "Pada tahap ini, data preprocessing adalah langkah penting untuk memastikan kualitas data sebelum digunakan dalam pelatihan model.\n",
    "\n",
    "Output tahap ini adalah dataset yang **sudah siap dipakai untuk training**, sehingga tahap modelling (Kriteria 2) **tidak perlu melakukan preprocessing lagi**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Og8pGV0-iDLz"
   },
   "outputs": [],
   "source": [
    "# ---- CONFIG ----\n",
    "TARGET_COL = \"target\"\n",
    "OUT_DIR = Path(\"preprocessing/creditscoring_preprocessing\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_PATH = OUT_DIR / \"creditscoring_preprocessed.csv\"\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"Kolom target '{TARGET_COL}' tidak ditemukan. Kolom tersedia: {list(df.columns)}\")\n",
    "\n",
    "# ---- BASIC CLEANING ----\n",
    "df_prep = df.drop_duplicates().copy()\n",
    "\n",
    "# imputasi sederhana: numerik -> median, kategorikal -> modus\n",
    "for col in df_prep.columns:\n",
    "    if col == TARGET_COL:\n",
    "        continue\n",
    "    if pd.api.types.is_numeric_dtype(df_prep[col]):\n",
    "        df_prep[col] = df_prep[col].fillna(df_prep[col].median())\n",
    "    else:\n",
    "        mode_val = df_prep[col].mode(dropna=True)\n",
    "        df_prep[col] = df_prep[col].fillna(mode_val.iloc[0] if len(mode_val) else \"\")\n",
    "\n",
    "# ---- ENCODING (One-Hot) ----\n",
    "X = df_prep.drop(columns=[TARGET_COL])\n",
    "y = df_prep[TARGET_COL]\n",
    "\n",
    "X_enc = pd.get_dummies(X, drop_first=False)\n",
    "\n",
    "df_out = pd.concat([X_enc, y], axis=1)\n",
    "df_out.to_csv(OUT_PATH, index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_PATH)\n",
    "print(\"Output shape:\", df_out.shape)\n",
    "df_out.head()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
