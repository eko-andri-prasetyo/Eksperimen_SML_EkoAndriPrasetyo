{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZLRMFl0JyyQ"
      },
      "source": [
        "# **1. Perkenalan Dataset**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hssSDn-5n3HR"
      },
      "source": [
        "Tahap pertama, Anda harus mencari dan menggunakan dataset dengan ketentuan sebagaimana yang sudah ditentukan.\n",
        "\n",
        "### Dataset yang digunakan\n",
        "Saya menggunakan dataset **Credit Scoring (synthetic)** yang disimpan di repository ini (format CSV).\n",
        "\n",
        "- **Sumber data (tautan):**\n",
        "  - GitHub (view): https://github.com/eko-andri-prasetyo/Eksperimen_SML_EkoAndriPrasetyo/blob/main/creditscoring_raw/creditscoring_raw.csv\n",
        "  - GitHub (raw): https://raw.githubusercontent.com/eko-andri-prasetyo/Eksperimen_SML_EkoAndriPrasetyo/main/creditscoring_raw/creditscoring_raw.csv\n",
        "- **Lokasi file raw di repo:** `creditscoring_raw/creditscoring_raw.csv`\n",
        "- **Jumlah data:** 2000 baris, 11 kolom (10 fitur + 1 target)\n",
        "- **Target:** `target` (0 = tidak default, 1 = default)\n",
        "- **Fitur:**\n",
        "  - Numerik: `age`, `monthly_income`, `loan_amount`, `tenure_months`, `num_credit_lines`, `has_previous_default`\n",
        "  - Kategorikal: `job_type`, `education_level`, `city`, `marital_status`\n",
        "- **Catatan kualitas data:** terdapat missing value pada `num_credit_lines`, `job_type`, dan `education_level` sehingga perlu imputasi pada tahap preprocessing.\n",
        "\n",
        "Catatan: Dataset ini bersifat **synthetic (dibuat untuk kebutuhan latihan/proyek)** dan disediakan di repo agar dapat diakses reviewer dengan mudah.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKADPWcFKlj3"
      },
      "source": [
        "# **2. Import Library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgA3ERnVn84N"
      },
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning atau deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YIEnAFKrKL"
      },
      "source": [
        "# **3. Memuat Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey3ItwTen_7E"
      },
      "source": [
        "Pada tahap ini, Anda perlu memuat dataset ke dalam notebook. Jika dataset dalam format CSV, Anda bisa menggunakan pustaka pandas untuk membacanya. Pastikan untuk mengecek beberapa baris awal dataset untuk memahami strukturnya dan memastikan data telah dimuat dengan benar.\n",
        "\n",
        "Jika dataset berada di Google Drive, pastikan Anda menghubungkan Google Drive ke Colab terlebih dahulu. Setelah dataset berhasil dimuat, langkah berikutnya adalah memeriksa kesesuaian data dan siap untuk dianalisis lebih lanjut.\n",
        "\n",
        "Jika dataset berupa unstructured data, silakan sesuaikan dengan format seperti kelas Machine Learning Pengembangan atau Machine Learning Terapan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "outputs": [],
      "source": [
        "RAW_PATH = Path(\"creditscoring_raw/creditscoring_raw.csv\")\n",
        "df = pd.read_csv(RAW_PATH)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgZkbJLpK9UR"
      },
      "source": [
        "# **4. Exploratory Data Analysis (EDA)**\n",
        "\n",
        "Pada tahap ini, Anda akan melakukan **Exploratory Data Analysis (EDA)** untuk memahami karakteristik dataset.\n",
        "\n",
        "Tujuan dari EDA adalah untuk memperoleh wawasan awal yang mendalam mengenai data dan menentukan langkah selanjutnya dalam analisis atau pemodelan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKeejtvxM6X1"
      },
      "outputs": [],
      "source": [
        "# Info ringkas dataset\n",
        "df.info()\n",
        "\n",
        "# Statistik deskriptif kolom numerik\n",
        "df.describe().T\n",
        "\n",
        "# Cek missing values\n",
        "missing = df.isna().sum().sort_values(ascending=False)\n",
        "missing[missing > 0]\n",
        "\n",
        "# Distribusi target (jika ada)\n",
        "if \"target\" in df.columns:\n",
        "    df[\"target\"].value_counts(dropna=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpgHfgnSK3ip"
      },
      "source": [
        "# **5. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COf8KUPXLg5r"
      },
      "source": [
        "Pada tahap ini, data preprocessing adalah langkah penting untuk memastikan kualitas data sebelum digunakan dalam pelatihan model.\n",
        "\n",
        "Output tahap ini adalah dataset yang **sudah siap dipakai untuk training**, sehingga tahap modelling (Kriteria 2) **tidak perlu melakukan preprocessing lagi**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og8pGV0-iDLz"
      },
      "outputs": [],
      "source": [
        "# ---- CONFIG ----\n",
        "TARGET_COL = \"target\"\n",
        "OUT_DIR = Path(\"preprocessing/creditscoring_preprocessing\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OUT_PATH = OUT_DIR / \"creditscoring_preprocessed.csv\"\n",
        "\n",
        "if TARGET_COL not in df.columns:\n",
        "    raise ValueError(\n",
        "        f\"Kolom target '{TARGET_COL}' tidak ditemukan. Kolom tersedia: {list(df.columns)}\"\n",
        "    )\n",
        "\n",
        "# ---- BASIC CLEANING ----\n",
        "df_prep = df.drop_duplicates().copy()\n",
        "\n",
        "# imputasi sederhana: numerik -> median, kategorikal -> modus\n",
        "num_cols = [c for c in df_prep.columns if c != TARGET_COL and pd.api.types.is_numeric_dtype(df_prep[c])]\n",
        "cat_cols = [c for c in df_prep.columns if c != TARGET_COL and not pd.api.types.is_numeric_dtype(df_prep[c])]\n",
        "\n",
        "for col in num_cols:\n",
        "    df_prep[col] = df_prep[col].fillna(df_prep[col].median())\n",
        "\n",
        "for col in cat_cols:\n",
        "    mode_val = df_prep[col].mode(dropna=True)\n",
        "    df_prep[col] = df_prep[col].fillna(mode_val.iloc[0] if len(mode_val) else \"\")\n",
        "\n",
        "# pastikan target integer (0/1)\n",
        "df_prep[TARGET_COL] = df_prep[TARGET_COL].astype(int)\n",
        "\n",
        "# ---- ENCODING (One-Hot) ----\n",
        "X = df_prep.drop(columns=[TARGET_COL])\n",
        "y = df_prep[TARGET_COL]\n",
        "\n",
        "X_enc = pd.get_dummies(X, drop_first=False)\n",
        "\n",
        "df_out = pd.concat([X_enc, y], axis=1)\n",
        "\n",
        "# ---- SAVE ----\n",
        "df_out.to_csv(OUT_PATH, index=False)\n",
        "\n",
        "print(\"Saved:\", OUT_PATH)\n",
        "print(\"Output shape:\", df_out.shape)\n",
        "df_out.head()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}